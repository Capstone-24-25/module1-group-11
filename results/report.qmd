---
title: "Biomarkers of ASD"
subtitle: "If you want a subtitle put it here"
author: "List names here"
date: last-modified
published-title: "Updated"
editor: visual
format: html
code-copy: true
execute:
  message: false
  warning: false
  echo: false
  cache: true
---

Use this as a template. Keep the headers and remove all other text. In all, your report can be quite short. When it is complete, render and then push changes to your team repository.

```{r}
# load any other packages and read data here
library(tidyverse)
library(infer)
library(randomForest)
library(tidymodels)
library(modelr)
library(yardstick)
library(ggplot2)
library(glmnet)
```

## Abstract

Write a brief one-paragraph abstract that describes the contents of your write-up.

## Dataset

The study obtained data from blood samples of individuals with autism spectrum disorder (ASD) and control/typically developing (TD) participants to identify potential early biological markers for ASD. The sample includes 154 male pediatric subjects with 76 subjects in the ASD group and 78 subjects in the TD group, with ages ranging from 18 months to 8 years old. The data was obtained through a fasting blood draw performed on both subject groups. Initially, the assay measured 1,317 proteins in 150Î¼l serum in 154 samples. However, 192 proteins failed to pass quality control and were removed leaving a total of 1,125 proteins to be analyzed. Thus, the dataset comprises 1,125 variables and 154 observations. Preprocessing consisted of log10 and z-transformations to normalize the data as well as clipping any z-transformed values less than -3 and greater than 3 to -3 and 3, respectively to address outliers. 

## Summary of published analysis

Summarize the methodology of the paper in 1-3 paragraphs. You need not explain the methods in depth as we did in class; just indicate what methods were used and how they were combined. If possible, include a diagram that depicts the methodological design. (Quarto has support for [GraphViz and Mermaid flowcharts](https://quarto.org/docs/authoring/diagrams.html).) Provide key results: the proteins selected for the classifier and the estimated accuracy.

## Findings

### Impact of Preprocessing



### Impact of Outliers

After taking the log-transformed data, we counted the number of proteins that exceeded a transformed level of 3, which we would consider an outlier, for each subject in order identify subjects with outlier protein profiles. Below is a boxplot describing the distribution of the number of outlier proteins for each subjects divided between subjects with ASD and subjects considered typically developing(TD).

```{r Outlier-Graph, echo=FALSE, warning=FALSE, message=FALSE}
load("../data/biomarker_no_trim.RData")
biomarker_no_trim %>%
  ggplot(aes(x = group, y = outlier_proteins)) + geom_boxplot() + labs(x = 'Group', y = 'Number of Outlier Proteins in Each Subject', title = 'Distribution of Total of Outlier Proteins in Subjects by Group')

# summarize distributions
asd_profile <- biomarker_no_trim %>% 
  filter(group == 'ASD') %>% 
  pull(outlier_proteins)

td_profile <- biomarker_no_trim %>% 
  filter(group == 'TD') %>% 
  pull(outlier_proteins)
```

The group of subjects with ASD had a total of `r sum(asd_profile)` outlier proteins while the typically developing group had larger a total of `r sum(td_profile)`. The graph shows similar distributions with typically developing subjects having a mean total of **`r round(mean(td_profile), 2)`** outlier proteins, and subjects with ASD having a lower mean total of **`r round(mean(asd_profile), 2)`**. Both groups share a median total of proteins per subject of **`r median(asd_profile)`**.

We also examined the proteins most prone to being outliers:

```{r Outlier-Proteins, echo=FALSE, warning=FALSE, message=FALSE}
outlier_count <-(biomarker_no_trim[, -c(1, 2, 3)] >= 3) %>% 
  colSums() %>% 
  as.data.frame() %>% 
  rename(outliers = 1) %>% 
  arrange(desc(outliers)) 

outlier_count %>% 
  ggplot(aes(outliers)) + geom_histogram(binwidth = 1, fill='lightblue3') + labs(x = "Number of Outlier Subjects per Protein", y = 'Count', title = "Distribution of Number of Outlier Subjects per Protein")

outlier_groups <- outlier_count %>% 
  group_by(outliers) %>% 
  count()
```

**A total of 722 of the proteins have 0 or 1 outliers across subjects.** The proteins with the highest count of outliers across subjects include **TLR2 with 7 outlier values**, and **IL-13, TGM3, GM-CSF, and hnRNP K, and SOD3 each with 6 outlier values.**

### Methodological variations

The benchmark protein panel was using 4 proteins which resulted in a sensitivity of 0.875 and accuracy of 0.839. Our goal now is to determine alternate methods to extract a comparable panel that can reproduce similar resulting values. First we will partition the data into a training and testing set, using the training data to select the protein panel. Using a t-test and random forest variable importance we extract two different protein panels which we will then determine our final panel by selecting intersecting proteins from both tests. Our result is 4 selected proteins, which when fitted to the testing data returned a sensitivity of 0.769 and accuracy of 0.677. Despite using the same method to derive our protein panel, our panel provides a weaker accuracy of the data. This is most likely due to the variability of a training and testing set. Because we do not have the entire data to find significant proteins, it leaves room for error when finding proteins. The metrics of the fitted model is provided below:

```{r}
read_csv("../data/part_1_result.csv")
```

The next step is to attempt a panel with more proteins. For both the t-test and logistical regression, we selected 25 potentially significant proteins from both to then intersect and find our panel. This method produced us a panel of 13 proteins, with a resulting sensitivity of 0.8125 and accuracy of 0.839, significantly better than our smaller panel of 4 proteins. Our results have improved significantly as we have included additional variables to estimate the result. The additional proteins we employed in testing may still have some significance towards our estimates, hence why it performed better, just because they weren't significant enough they still have some correlation to the outcome.

```{r}
read_csv("../data/part_2_result.csv")

```

Finally, we will make a panel using the original selection of 10 proteins using t-testing and random forests, but we will employ fuzzy intersection to determine the final panel. The result is a panel of 6 proteins that have a sensitivity of 0.75 and a accuracy of 0.774 after testing on the testing data. Using fuzzy intersection did not improve estimates to the same level of our benchmark, but it still produced pretty impressive accuracy results. Compared to our first panel of 4 proteins the fuzzy intersection had worse sensitivity, but had much more accuracy.

```{r}
read_csv("../data/part_3_result.csv")

```

### Improved classifier

Now that we have looked at methodical variations with the way we select our protein panel, we will now attempt to find a panel that has better accuracy than the benchmark panel.

Our first attempt was to use correlation to determine significant proteins. As in the previous section, we will partition the data first to create a training and testing set, and filter the data so we are just looking at participants who have ASD. We then determined the correlation of each variable, selecting the 2 proteins that had the highest absolute value of the correlation. Our resulting accuracy was 0.613 when testing on the testing data, so while this was a simpler panel, its estimates were far from comparable to our benchmark panel.

```{r}
read_csv("../data/method_1_result.csv")

```

Our second attempt was using LASSO regression to find our panel. First we tuned and fitted the Lasso model using deviance as our measure. The deviance graph with respect to the lamba value(the threshold) is shown below:

```{r}
# create class variable
biomarker_LASSO = biomarker_clean %>% 
  select(-ados) %>% 
  mutate(class = as.numeric(group == 'ASD'))

set.seed(101622)
partitions <- biomarker_LASSO %>%
  initial_split(prop = 0.8)

x_train <- training(partitions) %>%
  select(-group, -class) %>%
  as.matrix()
y_train <- training(partitions) %>%
  pull(class)

# tune and fit the LASSO model
plot(cv.glmnet(x_train, y_train, family = 'binomial', type.measure = 'deviance'))
```

Note that the suggested lambda range is between -2 and -3. However, since the purpose of this method is to create a "simpler" panel with less proteins, we then found a lambda, e\^(-1.8), that have a low deviance and allowed for a small protein panel. The result of using this lambda was a panel of 3 proteins, which when tested on the testing set returned an accuracy of 0.871. This result improved upon our benchmark of 0.831 with a smaller panel, so we were successful in finding a simple panel with comparable results.

```{r}
read_csv("../data/method_2_result.csv")

```
